app {
  #application name
  name: "DoubleVerifyPinnacleApiActualsDPP"
  #blossom id of th project. Get blossom id from blossom application
  blossomID: "CI02995445",
  #team name
  teamName: "DataSciences-DE-MDF-TM"
  #Contact details
  contactDetails: "DataSciences-DE-MDF-TM@Target.com",
  channel:"#mdf-success-mgs",
  env: "local",
  sla: "11:00 AM",
  fromAddress: "SVMDEDMP"
  toAddress:  "sudhindra.ramakrishna@target.com"

  queueName="SVMDEDMD_AUTO"
  executionEngine="tez"
  dynamicPartition="true"
  dynamicPartitionMode="nonstrict"
  jdbcUrl="jdbc:hive2://brcn1003.target.com:2181,brcn1004.target.com:2181,brcn1008.target.com:2181,brcn1009.target.com:2181,brcn1012.target.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2"
  hiveTezInputFormat="org.apache.hadoop.hive.ql.io.HiveInputFormat"
  mapReduceJobReduces="50"
  jdbcHiveDriver="org.apache.hive.jdbc.HiveDriver"

  irApiOrderTcinFndTable="stg_mdf_fnd.impactradius_api_order_tcin"
  irOrderStageTable="stg_mdf_stg.impactradius_order"
  irOrderGuestStgTable="stg_mdf_stg.impactradius_order_guest"
  irOrderGuestSalesStgTable="stg_mdf_stg.impactradius_order_guest_sales"

  tempIrOrderExtLocation = "src/test/data/sftpTransfer/hive/impactradius_guest_status/irorder",
  tempIrOrderGuestExtLocation = "src/test/data/sftpTransfer/hive/impactradius_guest_status/irorderguest",
  tempIrOrderGuestSalesExtLocation = "src/test/data/sftpTransfer/hive/impactradius_guest_status/irorderguestsales",
  #save final DF to hdfs before moving to sftpHdfsFileLocationPath after rename
  tempIrGuestStatusDeltaExtLocation = "src/test/data/sftpTransfer/hive/impactradius_guest_status/irgueststatusdelta/tmp",
  #to move file to edgenode
  irGuestStatusExportTempFolder = "src/test/data/sftpTransfer/fileexpress/temp"
  irGuestStatusExportFolder = "src/test/data/sftpTransfer/fileexpress/export"

   #Sftp
   sftpPrivateKeyPath = "src/test/data/sftpTransfer/fileexpress/key/privatekey"
   sftpUser="mdf_impact_radius_to_fex_dst"
   sftpHost="fileexpress-test.target.com"
   sftpPort=22
   sftpFileLocationPath="/"
   hdfsFileLocationPath="src/test/data/sftpTransfer/hive/hdfs"
   hdfsSearchFilePattern=""
   sftpSearchFilePattern=""


  lockLocation="src/test/data/sftpTransfer/landing/impactradius_guest_status/configurations/dpp_lock"
  #Used for write to external table
  fndExtLocation = "src/test/data/sftpTransfer/hive/stg_mdf_fnd/impactradius_guest_status"
  #tempFNDExtLocation = "src/test/hive/impactradius_guest_status/stage",
  deltaFndExtLocation = "src/test/data/sftpTransfer/hive/stg_mdf_fnd/impactradius_guest_status_delta"
  deltaFndExtTable = "impactradius_guest_status_delta"
  guestSalesTable="prd_gdp_fnd.guest_sales_all"




  #spark session creation properties
    spark_sources_partitionOverwriteMode="static"
    hive_partition_mode="nonstrict"
    spark_orc_impl="native"
    spark_enableVectorizedReader="true"
    spark_wareHouseLocation="/apps/hive/warehouse"
    hive_max_dynamic_partitions="2000"
    dqThreshold="1"

    # slack
    channel="#mdf-success-mgs-test"
    dq_channel="#mdf-success-mgs-test"
    failure_channel="#mdf-alert-msgs-test"
    errChannel="#mdf-alert-msgs-test"
    slackWebHook="https://api.target.com/slack_events/v1/webhooks/"
    dq_channelID="dStqc8EeBLuKxRu5hdV4I0gWk0V4TPBnQ108UL2rwlEy7Xm4enCar6xMJ9Jp4IPn"
    alert_channelID="syDd4MKrWEbL7GtNlptYM2040rSGhg1ASZvdtqJmjccsueXq7dnWC9NYUfVCy5lz"

    #DB schema names
    fndSchema = "stg_mdf_fnd"
    stgSchema = "stg_mdf_stg"
    lndSchema = "stg_mdf_lzn"
    wrkSchema = "stg_mdf_stg"

    #DB table names
    coreHistTable ="impactradius_guest_status"
    fndExtTable ="impactradius_guest_status_stg"


    atomicHistPartitionColumnName="report_d"
    coreHistPartitionColumnName="report_d"

    #coalesce to be done for each stage. For demo we are taking this as global value.
    # Value should be calculated based on expected load
    coalesceFactor=1
    #numberOfPartitions
    #the max partitions allowed to be written into the path provided
    numberOfPartitions=10
    influxdb {
        #measurement name got from measurement team
        measurementName = "impactradius-guest-status-dpp-stg"
        #end point of influx to push data
        grafanaEndPoint = "https://metricsfrontdoor-shared.prod.target.com/write?db=metrics"
    }

    metrics {
          metricsKafkaPush=false
          metricsInfluxPush=true
    }


}